{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.datasets import mnist\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Core_Functions import multi_hot_encoding\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a defined number of image paires from a given dataset\n",
    "def get_left_min_image_combinations(number_image_pairs_selected, image_data, image_labels):\n",
    "    \n",
    "    num_images_total = len(image_labels)\n",
    "    \n",
    "    image_combination_data = []\n",
    "    image_combination_labels = []\n",
    "    \n",
    "    for i in range(number_image_pairs_selected):\n",
    "        \n",
    "        # Draw two image indices from a uniform random distribution\n",
    "        random_index_A = random.randint(0, num_images_total-1)\n",
    "        random_index_B = random.randint(0, num_images_total-1)\n",
    "        \n",
    "        # Randomly choose two images from the dataset\n",
    "        image_A = image_data[random_index_A]\n",
    "        image_B = image_data[random_index_B]\n",
    "        \n",
    "        # Merge images TODO: this could be a function with several options\n",
    "        combined_images = np.hstack((image_A, image_B))\n",
    "        \n",
    "        # Find the minimum between the two labels\n",
    "        label_A = image_labels[random_index_A]\n",
    "        label_B = image_labels[random_index_B]\n",
    "        minimum_label = min(label_A, label_B)\n",
    "        \n",
    "        if label_A < label_B:\n",
    "            # Merge images TODO: this could be a function with several options\n",
    "            combined_images = np.hstack((image_A, image_B))\n",
    "            image_combination_data.append(combined_images)\n",
    "            image_combination_labels.append([min(label_A, label_B), max(label_A,label_B)])\n",
    "        elif label_A > label_B: \n",
    "            # Merge images TODO: this could be a function with several options\n",
    "            combined_images = np.hstack((image_B, image_A))\n",
    "            image_combination_data.append(combined_images)\n",
    "            image_combination_labels.append([min(label_A, label_B), max(label_A,label_B)])\n",
    "        # Here we want to exclude the images where they are the same on both sides\n",
    "\n",
    "        \n",
    "        \n",
    "    # Convert image data and labels lists to numpy arrays\n",
    "    image_combination_data = np.array(image_combination_data)\n",
    "    image_combination_labels = np.array(image_combination_labels)\n",
    "    \n",
    "    return image_combination_data, image_combination_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a defined number of image paires from a given dataset\n",
    "def get_right_min_image_combinations(number_image_pairs_selected, image_data, image_labels):\n",
    "    \n",
    "    num_images_total = len(image_labels)\n",
    "    \n",
    "    image_combination_data = []\n",
    "    image_combination_labels = []\n",
    "    \n",
    "    for i in range(number_image_pairs_selected):\n",
    "        \n",
    "        # Draw two image indices from a uniform random distribution\n",
    "        random_index_A = random.randint(0, num_images_total-1)\n",
    "        random_index_B = random.randint(0, num_images_total-1)\n",
    "        \n",
    "        # Randomly choose two images from the dataset\n",
    "        image_A = image_data[random_index_A]\n",
    "        image_B = image_data[random_index_B]\n",
    "        \n",
    "        # Merge images TODO: this could be a function with several options\n",
    "        combined_images = np.hstack((image_A, image_B))\n",
    "        \n",
    "        # Find the minimum between the two labels\n",
    "        label_A = image_labels[random_index_A]\n",
    "        label_B = image_labels[random_index_B]\n",
    "        minimum_label = min(label_A, label_B)\n",
    "        \n",
    "        if label_A < label_B:\n",
    "            # Merge images TODO: this could be a function with several options\n",
    "            combined_images = np.hstack((image_B, image_A))\n",
    "            # Append newly generated image combination and minimum label to list\n",
    "            image_combination_data.append(combined_images)\n",
    "            image_combination_labels.append([min(label_A, label_B), max(label_A,label_B)])\n",
    "        elif label_A > label_B: \n",
    "            # Merge images TODO: this could be a function with several options\n",
    "            combined_images = np.hstack((image_A, image_B))\n",
    "            # Here we want to exclude the images where they are the same on both sides\n",
    "            # Append newly generated image combination and minimum label to list\n",
    "            image_combination_data.append(combined_images)\n",
    "            image_combination_labels.append([min(label_A, label_B), max(label_A,label_B)])\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    # Convert image data and labels lists to numpy arrays\n",
    "    image_combination_data = np.array(image_combination_data)\n",
    "    image_combination_labels = np.array(image_combination_labels)\n",
    "    \n",
    "    return image_combination_data, image_combination_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split into training and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set further into training and validation sets\n",
    "sample_size = 40000\n",
    "X_train, X_val, y_train, y_val = train_images[:sample_size], train_images[sample_size:sample_size*2],  train_labels[:sample_size], train_labels[sample_size:sample_size*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_train_X, combo_train_y = get_left_min_image_combinations(40000, X_train, y_train)\n",
    "combo_val_X, combo_val_y = get_right_min_image_combinations(20000, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data so they can be fed into the network, one-hot-encode the labels\n",
    "\n",
    "train_images = combo_train_X.reshape((combo_train_X.shape[0], 28* 56))\n",
    "train_images = train_images/ 255\n",
    "\n",
    "val_images = combo_val_X.reshape((combo_val_X.shape[0], 28* 56))\n",
    "val_images = val_images/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35860, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here instead of using to_categorical, I use my custom multi-hot encoding\n",
    "\"\"\"\n",
    "train_labels = to_categorical(combo_train_y)\n",
    "val_labels = to_categorical(combo_val_y)\n",
    "\"\"\"\n",
    "\n",
    "train_labels = np.array(multi_hot_encoding.multi_hot_encode(combo_train_y))\n",
    "val_labels =  np.array(multi_hot_encoding.multi_hot_encode(combo_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "\n",
    "num_epochs = 5\n",
    "num_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "def build_DNN():\n",
    "\n",
    "    inputs = keras.Input(shape=(28* 56,))\n",
    "\n",
    "    dense = layers.Dense(512, activation=\"relu\")\n",
    "    x = dense(inputs)\n",
    "\n",
    "    outputs = layers.Dense(10, \"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs,\n",
    "                       outputs = outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        metrics=[\"accuracy\", \"mae\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1568)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               803328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 808,458\n",
      "Trainable params: 808,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DNN_model = build_DNN()\n",
    "DNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 0.0010 - accuracy: 0.7898 - mae: 7.8863e-04\n",
      "Epoch 2/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 7.0391e-04 - accuracy: 0.8092 - mae: 5.9451e-04\n",
      "Epoch 3/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 6.3012e-04 - accuracy: 0.8269 - mae: 4.9290e-04\n",
      "Epoch 4/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 5.4167e-04 - accuracy: 0.8422 - mae: 4.2201e-04\n",
      "Epoch 5/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 4.2228e-04 - accuracy: 0.8558 - mae: 3.1217e-04\n",
      "Epoch 6/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 2.8965e-04 - accuracy: 0.8622 - mae: 2.3778e-04\n",
      "Epoch 7/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 2.4193e-04 - accuracy: 0.8781 - mae: 1.8670e-04\n",
      "Epoch 8/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 1.7309e-04 - accuracy: 0.8855 - mae: 1.4311e-04\n",
      "Epoch 9/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 2.0503e-04 - accuracy: 0.8969 - mae: 1.3667e-04\n",
      "Epoch 10/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 1.3211e-04 - accuracy: 0.9033 - mae: 9.8851e-05\n",
      "Epoch 11/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 9.2099e-05 - accuracy: 0.9088 - mae: 7.7722e-05\n",
      "Epoch 12/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 7.4526e-05 - accuracy: 0.9134 - mae: 5.9210e-05\n",
      "Epoch 13/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 6.0819e-05 - accuracy: 0.9221 - mae: 4.5521e-05\n",
      "Epoch 14/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 5.0497e-05 - accuracy: 0.9263 - mae: 3.8163e-05\n",
      "Epoch 15/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 3.0778e-05 - accuracy: 0.9303 - mae: 2.8205e-05\n",
      "Epoch 16/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 2.8026e-05 - accuracy: 0.9367 - mae: 2.3857e-05\n",
      "Epoch 17/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 4.5784e-05 - accuracy: 0.9427 - mae: 2.2862e-05\n",
      "Epoch 18/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 9.1620e-06 - accuracy: 0.9452 - mae: 8.6981e-06\n",
      "Epoch 19/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 8.1826e-06 - accuracy: 0.9523 - mae: 7.5445e-06\n",
      "Epoch 20/20\n",
      "561/561 [==============================] - 2s 3ms/step - loss: 5.8961e-06 - accuracy: 0.9559 - mae: 5.5200e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16fb34820>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "DNN_model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs = 20, \n",
    "          batch_size = 64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 1s 1ms/step - loss: 23.4337 - accuracy: 0.0037 - mae: 0.4577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23.433746337890625, 0.0037121169734746218, 0.457720011472702]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print loss, mae and accuracy\n",
    "DNN_eval_model = DNN_model.evaluate(val_images, val_labels)\n",
    "DNN_eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting that the DNN is slightly better than the CNN at this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLotting\n",
    "plt.title('Comparing validation accuracy between DNN and CNN')\n",
    "plt.bar(['DNN','CNN'], [DNN_eval_model[1],CNN_eval_model[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ML",
   "language": "python",
   "name": "general_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
